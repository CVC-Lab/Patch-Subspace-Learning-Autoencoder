# -*- coding: utf-8 -*-
"""vae

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18G2qfw4556HmqPSKd69xYs5YC6IuzWVY

## Setup
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
    raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

from autoencoder import *

cwd = ''

"""## Load Dataset"""

validation_images = load_images(cwd + 'validation-r08-s-0000-of-0040.tfrecords')
images = load_images(cwd + 'train-r08-s-0000-of-0120.tfrecords')

# data = read_images(cwd + '/canon')

"""## Generate Blur Images"""

blur_imgs = gen_noise(images)
val_blur_imgs = gen_noise(validation_images)

"""## Divide and Merge Images"""

# block_size = 18 #28
# num_block = 18 #22
# block_per_image = num_block * num_block #484
# overlap = 4 #8
# num_cluster = 2
# shape = (block_size, block_size, 3)

clear_images, blur_images = gen_train_set(images, blur_imgs, block_size=block_size)


"""## Create a sampling layer"""

class Sampling(layers.Layer):
    """Uses (z_mean, z_log_var) to sample z, the vector encoding a digit."""

    def call(self, inputs):
        z_mean, z_log_var = inputs

        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon

"""## Build the encoder and decoder"""

latent_dim = 60
regularizer = keras.regularizers.l1_l2(0.01)

def build_encoder(latent_dim, shape, num_cluster):
  encoder_inputs = keras.Input(shape=shape)
  x = layers.Conv2D(16, 3, activation="relu", strides=1, padding="same", 
                    kernel_regularizer=regularizer)(encoder_inputs)
  x = layers.Conv2D(32, 3, activation="relu", strides=2, padding="same",
                    kernel_regularizer=regularizer)(x)
  x = layers.Conv2D(48, 3, activation="relu", strides=1, padding="same", 
                    kernel_regularizer=regularizer)(x)
  x = layers.Conv2D(72, 3, activation="relu", strides=2, padding="same", 
                    kernel_regularizer=regularizer)(x)
  x = layers.Conv2D(128, 3, activation="relu", strides=1, padding="same", 
                    kernel_regularizer=regularizer)(x)
  x = tf.keras.layers.BatchNormalization()(x)

  x = layers.Flatten()(x)
  x = layers.Dense(96, activation="relu", 
                   kernel_regularizer=regularizer)(x)
  x = layers.Dense(latent_dim, activation="relu", 
                   kernel_regularizer=regularizer)(x)

  initializer = tf.keras.initializers.RandomNormal(1, 0.1)
  y = layers.Dense(num_cluster, activation="relu",
                   kernel_initializer=initializer, 
                   trainable = False)(x)
  y = layers.Softmax()(y)

  # Sampling
  z_mean = layers.Dense(latent_dim, name="z_mean")(x)
  z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)
  z = Sampling()([z_mean, z_log_var])
  encoder = keras.Model(encoder_inputs, [x, y, z_mean, z_log_var, z], name="encoder")
  return encoder

def build_decoder(latent_dim, shape, name):
  latent_inputs = keras.Input(shape=(latent_dim,))
  x = layers.Dense(shape[0] * shape[1] * 4, activation="relu",
                   kernel_regularizer=regularizer)(latent_inputs)
  x = layers.Reshape((shape[0]//6, shape[1]//6, 144))(x)
  x = layers.Conv2DTranspose(128, 3, activation="relu", strides=1, 
                             kernel_regularizer=regularizer, padding="same")(x)
  x = layers.Conv2DTranspose(72, 3, activation="relu", strides=2,
                             kernel_regularizer=regularizer, padding="same")(x)
  x = layers.Conv2DTranspose(48, 3, activation="relu", strides=1, 
                             kernel_regularizer=regularizer, padding="same")(x)
  x = layers.Conv2DTranspose(32, 3, activation="relu", strides=3, 
                             kernel_regularizer=regularizer, padding="same")(x)
  x = layers.Conv2DTranspose(16, 3, activation="relu", strides=1, 
                             kernel_regularizer=regularizer, padding="same")(x)
  decoder_outputs = layers.Conv2DTranspose(shape[2], 3, 
                                           activation="sigmoid", 
                                           kernel_regularizer=regularizer, 
                                           padding="same")(x)
  decoder = keras.Model(latent_inputs, decoder_outputs, name=name)
  return decoder

"""## Define the VAE as a `Model` with a custom `train_step`"""

class VAE(keras.Model):
    def __init__(self, encoder, decoder, num_cluster, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.num_cluster = num_cluster

    def train_step(self, data):
        test = data[0][1]
        data = data[0][0]
        shape = (len(data[0]), len(data[0][0]))

        with tf.GradientTape() as tape:
            x, y, z_mean, z_log_var, z = self.encoder(data)
            
            # reconstruct images
            reconstruction = self.decoder(z)
            # calculate loss
            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
            kl_loss = tf.reduce_mean(kl_loss)
            kl_loss *= -0.5

            reconstruction_loss = tf.reduce_mean(
                tf.keras.losses.MSE(test, reconstruction))
            reconstruction_loss *= shape[0] * shape[1]

            # leng = 0
            # for k in range(len(y)):
            #   leng += 1
            # soft_cut_loss = 0
            # for i in range(latent_dim):
            #   soft_cut_loss += soft_n_cut_loss(x[:,i], y, self.num_cluster, leng, 1)
            
            total_loss = reconstruction_loss + kl_loss #+ 0.1*soft_cut_loss
        
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        return {
            "reconstruction_loss": reconstruction_loss,
            "kl_loss": kl_loss,
            #"soft_n_cut_loss": soft_cut_loss,
        }

class VAE_P(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE_P, self).__init__(**kwargs)
        self.encoder = encoder
        self.trained_decoder = decoder

    def train_step(self, data):
        test = data[0][1]
        data = data[0][0]
        shape = (len(data[0]), len(data[0][0]))
        
        with tf.GradientTape() as tape:
            x, y, z_mean, z_log_var, z = self.encoder(data)
            # reconstruct images
            reconstruction = self.trained_decoder(z)
            # calculate loss
            reconstruction_loss = tf.reduce_mean(
                tf.keras.losses.MSE(test, reconstruction))
            reconstruction_loss *= shape[0] * shape[1]
            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
            kl_loss = tf.reduce_mean(kl_loss)
            kl_loss *= -0.5
            total_loss = reconstruction_loss + kl_loss
        
        grads = tape.gradient(total_loss, self.trained_decoder.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trained_decoder.trainable_weights))
        return {
            "reconstruction_loss": reconstruction_loss,
            "kl_loss": kl_loss,
        }

"""## Train the VAE"""

epoch = 100

lr_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.001,
    decay_steps=1000,
    decay_rate=0.9
)

encoder = build_encoder(latent_dim, shape, num_cluster)
decoder = build_decoder(latent_dim, shape,"decoder")
model = VAE(encoder, decoder, num_cluster)
model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule))
model.fit((blur_images,clear_images), epochs=epoch, batch_size=128)

# clustering
def clustering(blur_images, clear_images, num_clusters=2):
  batch = 10000
  x, y, z_mean, z_log_var, z = encoder(blur_images[:batch])
  for i in range(batch, len(blur_images), batch):
    y = np.concatenate([y, encoder(blur_images[i: i+batch])[1]], axis=0)
    x = np.concatenate([x, encoder(blur_images[i: i+batch])[0]], axis=0)
  labels = np.array(cluster_latent(y))

  clusters = gen_clusters(blur_images, labels, num_clusters)
  label_clusters = gen_clusters(clear_images, labels, num_clusters)
  clus = []
  for c in range(num_clusters):
    clus.append(np.array(clusters[c]))
  label_clus = []
  for c in range(num_clusters):
    label_clus.append(np.array(label_clusters[c]))
  return np.array(clus), np.array(label_clus)

clus, label_clus = clustering(blur_images, clear_images, num_cluster)

# train decoders
def train_decoders(clus, label_clus, encoder, epochs=100, batch_size=128, lr=lr_schedule):
    decoders = []
    for i in range(len(clus)):
        decoder_i = build_decoder(latent_dim, shape,"decoder"+str(i))
        if len(clus[i]) > 0:
            model_i = VAE_P(encoder, decoder_i)
            model_i.compile(optimizer=keras.optimizers.Adam(learning_rate=lr))
            model_i.fit((clus[i],label_clus[i]), epochs=epochs, batch_size=batch_size)
        decoders.append(decoder_i)
    return decoders

decoders = train_decoders(clus, label_clus, encoder, epoch)

"""## Evaluation"""

test_images_clear, test_images_blur = gen_train_set(
    validation_images, val_blur_imgs, block_size=block_size)

batch = 10000
x, y, z_mean, z_log_var, z = encoder.predict(test_images_blur[:batch])
for i in range(batch, len(test_images_blur), batch):
  y = np.concatenate([y, encoder.predict(test_images_blur[i: i+batch])[1]], axis=0)
  z = np.concatenate([z, encoder.predict(test_images_blur[i: i+batch])[4]], axis=0)

decoded_imgs = decoder.predict(z[:batch])
for i in range(batch, len(z), batch):
  decoded_imgs = np.concatenate([decoded_imgs, decoder.predict(z[i:i+batch])], axis=0)

"""## Metrics"""
recons_images = reconstruct_image(z, y,
                                  decoders=decoders,
                                  blocks_per_image=block_per_image,
                                  block_size=block_size)
recons_images = tf.cast((recons_images*255), dtype=tf.uint8)

comp_images = reconstruct_image(z, y, [decoder]*num_cluster,
                                blocks_per_image=block_per_image,
                                block_size=block_size)
comp_images = tf.cast((comp_images*255), dtype=tf.uint8)

test_images = validation_images
'''
PSNR
'''
cnt = 0
recons_psnr = []
comp_psnr = []
for i in range(len(recons_images)):
  recons_psnr.append(cv2.PSNR(recons_images[i].numpy(), test_images[i]))
  comp_psnr.append(cv2.PSNR(comp_images[i].numpy(), test_images[i]))
  if cv2.PSNR(recons_images[i].numpy(), test_images[i]) > cv2.PSNR(comp_images[i].numpy(), test_images[i]):
    cnt += 1
print(np.array(recons_psnr).mean(), np.array(comp_psnr).mean())
print(cnt/len(test_images))

'''
SSIM
'''
cnt = 0
recons_ssim = []
comp_ssim = []
for i in range(len(recons_images)):
  recons_ssim.append(ssim(recons_images[i].numpy(), test_images[i], multichannel=True))
  comp_ssim.append(ssim(comp_images[i].numpy(), test_images[i], multichannel=True))
  if ssim(recons_images[i].numpy(), test_images[i], multichannel=True) > ssim(comp_images[i].numpy(), test_images[i], multichannel=True):
    cnt += 1
print('SSIM')
print(np.array(recons_ssim).mean(), np.array(comp_ssim).mean())
print(cnt/len(test_images))

'''
UQI
'''
cnt = 0
recons_se = []
comp_se = []
for i in range(len(recons_images)):
  recons_se.append(sewar.full_ref.uqi(recons_images[i].numpy(), test_images[i], ws=8))
  comp_se.append(sewar.full_ref.uqi(comp_images[i].numpy(), test_images[i], ws=8))
  if sewar.full_ref.uqi(recons_images[i].numpy(), test_images[i], 
                        ws=8) > sewar.full_ref.uqi(comp_images[i].numpy(), test_images[i], ws=8):
    cnt += 1
print('UQI')
print(np.array(recons_se).mean(), np.array(comp_se).mean())
print(cnt/len(test_images))

